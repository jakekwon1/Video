{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import sys, cv2, glob\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_pretrained = keras.applications.vgg16.VGG16(weights = 'imagenet', include_top = True, input_shape = (224,224,3))\n",
    "\n",
    "print(vgg16_pretrained.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(vgg16_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_img = 'fig/car1.jpg'\n",
    "plane_img = 'fig/airplane_1.jpg'\n",
    "dog_img = 'fig/beagle.jpg'\n",
    "\n",
    "img = keras.preprocessing.image.load_img(car_img, target_size=(224,224))\n",
    "x = keras.preprocessing.image.img_to_array(img) # numpy로 바꿔줌\n",
    "x = np.expand_dims(x,axis=0)\n",
    "x = keras.applications.vgg16.preprocess_input(x)  # (x-128)/255 를 해주는 함수\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(x[0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output=vgg16_pretrained.predict(x)\n",
    "\n",
    "class_name = keras.applications.vgg16.decode_predictions(output,top = 3)  # np.argmax(output[0].flatten()) 중에 top 3개 표시\n",
    "\n",
    "print(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name = class_name[0][0][1]\n",
    "prob = class_name[0][0][2]\n",
    "\n",
    "print(name, prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_opencv = cv2.imread(car_img, cv2.IMREAD_REDUCED_COLOR_2)\n",
    "\n",
    "text = f'{name}, {prob * 100 :.2f}%'\n",
    "cv2.putText(img_opencv, text, (10,30), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 1, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('image', img_opencv)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = keras.preprocessing.image.load_img(plane_img, target_size=(224,224))\n",
    "x = keras.preprocessing.image.img_to_array(img) # numpy로 바꿔줌\n",
    "x = np.expand_dims(x,axis=0)\n",
    "x = keras.applications.vgg16.preprocess_input(x)  # (x-128)/255 를 해주는 함수\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(x[0])\n",
    "plt.show()\n",
    "\n",
    "output=vgg16_pretrained.predict(x)\n",
    "class_name = keras.applications.vgg16.decode_predictions(output,top = 3)  # np.argmax(output[0].flatten()) 중에 top 3개 표시\n",
    "# print(class_name)\n",
    "\n",
    "name = class_name[0][0][1]\n",
    "prob = class_name[0][0][2]\n",
    "# print(name, prob)\n",
    "\n",
    "\n",
    "img_opencv = cv2.imread(plane_img, cv2.IMREAD_REDUCED_COLOR_2)\n",
    "\n",
    "text = f'{name}, {prob * 100 :.2f}%'\n",
    "cv2.putText(img_opencv, text, (10,30), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 1, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('image', img_opencv)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = keras.preprocessing.image.load_img(dog_img, target_size=(224,224))\n",
    "x = keras.preprocessing.image.img_to_array(img) # numpy로 바꿔줌\n",
    "x = np.expand_dims(x,axis=0)\n",
    "x = keras.applications.vgg16.preprocess_input(x)  # (x-128)/255 를 해주는 함수\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(x[0])\n",
    "plt.show()\n",
    "\n",
    "output=vgg16_pretrained.predict(x)\n",
    "class_name = keras.applications.vgg16.decode_predictions(output,top = 3)  # np.argmax(output[0].flatten()) 중에 top 3개 표시\n",
    "# print(class_name)\n",
    "\n",
    "name = class_name[0][0][1]\n",
    "prob = class_name[0][0][2]\n",
    "# print(name, prob)\n",
    "\n",
    "\n",
    "img_opencv = cv2.imread(dog_img)\n",
    "\n",
    "text = f'{name}, {prob * 100 :.2f}%'\n",
    "cv2.putText(img_opencv, text, (10,30), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 1, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('image', img_opencv)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_pretrained = keras.applications.vgg16.VGG16(weights = 'imagenet', include_top = True, input_shape = (224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "img_paths = glob.glob('./fig/my_images/*.*')\n",
    "\n",
    "# display(img_paths)\n",
    "\n",
    "cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "cv2.setWindowProperty('image',cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "if img_paths is None:\n",
    "    print('image not found')\n",
    "\n",
    "idx = 0\n",
    "while True:\n",
    "    img = keras.preprocessing.image.load_img(img_paths[idx], target_size=(224,224))\n",
    "\n",
    "    if img is None:\n",
    "        print('image not found')\n",
    "        break\n",
    "    \n",
    "    x = keras.preprocessing.image.img_to_array(img)\n",
    "    x = np.expand_dims(x,axis=0)\n",
    "    x = keras.applications.vgg16.preprocess_input(x)\n",
    "    \n",
    "    output=vgg16_pretrained.predict(x)\n",
    "    class_name = keras.applications.vgg16.decode_predictions(output,top = 3)  # np.argmax(output[0].flatten()) 중에 top 3개 표시\n",
    "    \n",
    "    name = class_name[0][0][1]\n",
    "    prob = class_name[0][0][2]\n",
    "    \n",
    "    img_opencv = cv2.imread(img_paths[idx])\n",
    "\n",
    "    text = f'{name}, {prob * 100 :.2f}%'\n",
    "    cv2.putText(img_opencv, text, (10,30), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0,0,255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('image', img_opencv)\n",
    "    \n",
    "    \n",
    "    if  cv2.waitKey(3000) == 27:\n",
    "        break\n",
    "    idx += 1\n",
    "\n",
    "    if idx >= (len(img_paths)):\n",
    "        idx = 0\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_pretrained = keras.applications.vgg16.VGG16(weights = 'imagenet', include_top = True, input_shape = (224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape = (150,150,3))\n",
    "conv1 = keras.layers.Conv2D(64, kernel_size = 3, activation = 'relu')(inputs)\n",
    "conv2 = keras.layers.Conv2D(32, kernel_size = 3, activation = 'relu')(conv1)\n",
    "max_pool = keras.layers.MaxPool2D(pool_size = 2)(conv2)\n",
    "flatten = keras.layers.Flatten()(max_pool)\n",
    "dense1 = keras.layers.Dense(120, activation = 'relu')(flatten)\n",
    "drop_out = keras.layers.Dropout(0.3)(dense1)\n",
    "dense2 = keras.layers.Dense(32, activation = 'relu')(drop_out)\n",
    "outputs = keras.layers.Dense(1, activation = 'sigmoid')(dense2)\n",
    "\n",
    "alz_model = keras.Model(inputs = inputs, outputs = outputs)\n",
    "alz_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ad_img_path = glob.glob('fig/train/ad/*.*') + glob.glob('fig/test/ad/*.*')\n",
    "nor_img_path = glob.glob('fig/train/normal/*.*') + glob.glob('fig/test/normal/*.*')\n",
    "img_paths = ad_img_path + nor_img_path\n",
    "\n",
    "target = np.array([1]*len(ad_img_path) + [0]*len(nor_img_path))\n",
    "print(len(target))\n",
    "\n",
    "imgs = np.zeros((0,150,150,3), np.float32)\n",
    "\n",
    "for img_path in img_paths:\n",
    "    img = cv2.imread(img_path)\n",
    "    img = (img.astype(np.float32))/255.\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    imgs = np.append(imgs, img, axis=0)\n",
    "\n",
    "print(imgs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(imgs, target, test_size= 0.2,shuffle=True)\n",
    "\n",
    "print(x_train.shape,'\\n',y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alz_model.compile(loss='binary_crossentropy', optimizer='adam',metrics='acc')\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath= 'fig/alz_model.h5', save_best_only=True)\n",
    "earlystop = keras.callbacks.EarlyStopping(patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = alz_model.fit(x_train, y_train, epochs=200, batch_size=20, validation_data= (x_test, y_test), callbacks=[checkpoint, earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], color = 'b', label = 'train_loss')\n",
    "plt.plot(history.history['val_loss'], color = 'r', label = 'train_loss')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# alz_model.evaluate(x_test,y_test)\n",
    "X_test = np.expand_dims(x_test[0], axis=0)\n",
    "alz_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_vgg16 = keras.applications.vgg16.VGG16(weights= 'imagenet',include_top=False, input_shape=(150,150,3))\n",
    "transfer_vgg16.trainable = False\n",
    "\n",
    "transfer_vgg16.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sequential = keras.Sequential()\n",
    "Sequential.add(transfer_vgg16)\n",
    "Sequential.add(keras.layers.Flatten())\n",
    "Sequential.add(keras.layers.Dense(64, activation = 'relu'))\n",
    "Sequential.add(keras.layers.Dropout(0.3))\n",
    "Sequential.add(keras.layers.Dense(1,activation = 'sigmoid'))\n",
    "\n",
    "Sequential.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sequential.compile(loss='binary_crossentropy', optimizer='adam', metrics='acc')\n",
    "\n",
    "history = Sequential.fit(x_train, y_train, epochs=200, batch_size=20, validation_data= (x_test, y_test), callbacks=[checkpoint, earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], color = 'b', label = 'loss')\n",
    "plt.plot(history.history['val_loss'], color = 'r', label = 'val_loss')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
